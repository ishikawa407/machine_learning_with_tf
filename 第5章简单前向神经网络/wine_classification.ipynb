{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0     1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1     1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2     1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3     1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4     1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine_1</th>\n",
       "      <th>Wine_2</th>\n",
       "      <th>Wine_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wine_1  Wine_2  Wine_3\n",
       "0       1       0       0\n",
       "1       1       0       0\n",
       "2       1       0       0\n",
       "3       1       0       0\n",
       "4       1       0       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = df['Wine'].astype(\"str\")\n",
    "df_Y = pd.get_dummies(df_y)\n",
    "df_Y.columns = ['Wine_1', \"Wine_2\", \"Wine_3\"]\n",
    "df_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = df.drop(columns=[\"Wine\"])\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X, df_Y = shuffle(df_X, df_Y)\n",
    "std = StandardScaler()\n",
    "df_X = std.fit_transform(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(df_X, df_Y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Construct Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单层的全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(X, ow, b1):\n",
    "    a0 = X\n",
    "    a1 = (tf.matmul(ow, a0) + b1)\n",
    "    output = tf.nn.softmax(a1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ishikawa407/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(dtype=\"float\", shape=[13, None], name=\"X\")\n",
    "Y = tf.placeholder(dtype=\"float\", shape=[3, None], name=\"Y\")\n",
    "ow = tf.get_variable(shape=[3, 13], initializer=tf.contrib.layers.xavier_initializer(), name='ow')\n",
    "b1 = tf.Variable(tf.zeros([3, 1]))\n",
    "output = Model(X, ow, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(output),\n",
    "                                              reduction_indices=[0]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_train = {X: X_train.T,\n",
    "                   Y: Y_train.T}\n",
    "feed_dict_val = {X: X_val.T,\n",
    "                 Y: Y_val.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.2170796 Train accuary: 0.3380281690140845\n",
      "Val loss: 4.259977 Val accuary: 0.5833333333333334\n",
      "----------------------------\n",
      "Train loss: 5.9380155 Train accuary: 0.352112676056338\n",
      "Val loss: 4.1068196 Val accuary: 0.6111111111111112\n",
      "----------------------------\n",
      "Train loss: 5.686493 Train accuary: 0.3732394366197183\n",
      "Val loss: 3.9691794 Val accuary: 0.6111111111111112\n",
      "----------------------------\n",
      "Train loss: 5.461677 Train accuary: 0.4014084507042254\n",
      "Val loss: 3.8448818 Val accuary: 0.6111111111111112\n",
      "----------------------------\n",
      "Train loss: 5.2637463 Train accuary: 0.4295774647887324\n",
      "Val loss: 3.7329898 Val accuary: 0.5833333333333334\n",
      "----------------------------\n",
      "Train loss: 5.0932364 Train accuary: 0.49295774647887325\n",
      "Val loss: 3.6333034 Val accuary: 0.6111111111111112\n",
      "----------------------------\n",
      "Train loss: 4.9500775 Train accuary: 0.5774647887323944\n",
      "Val loss: 3.545863 Val accuary: 0.6388888888888888\n",
      "----------------------------\n",
      "Train loss: 4.8328032 Train accuary: 0.6549295774647887\n",
      "Val loss: 3.4705052 Val accuary: 0.75\n",
      "----------------------------\n",
      "Train loss: 4.7384405 Train accuary: 0.704225352112676\n",
      "Val loss: 3.4066021 Val accuary: 0.7777777777777778\n",
      "----------------------------\n",
      "Train loss: 4.663119 Train accuary: 0.7394366197183099\n",
      "Val loss: 3.3530617 Val accuary: 0.7777777777777778\n",
      "----------------------------\n",
      "Train loss: 4.6028852 Train accuary: 0.7676056338028169\n",
      "Val loss: 3.3085136 Val accuary: 0.7777777777777778\n",
      "----------------------------\n",
      "Train loss: 4.5542626 Train accuary: 0.8028169014084507\n",
      "Val loss: 3.2715318 Val accuary: 0.8055555555555556\n",
      "----------------------------\n",
      "Train loss: 4.5144706 Train accuary: 0.8169014084507042\n",
      "Val loss: 3.2407923 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.4813886 Train accuary: 0.8591549295774648\n",
      "Val loss: 3.215148 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.453447 Train accuary: 0.8732394366197183\n",
      "Val loss: 3.1936464 Val accuary: 0.8055555555555556\n",
      "----------------------------\n",
      "Train loss: 4.429491 Train accuary: 0.8802816901408451\n",
      "Val loss: 3.1755152 Val accuary: 0.8055555555555556\n",
      "----------------------------\n",
      "Train loss: 4.408671 Train accuary: 0.8943661971830986\n",
      "Val loss: 3.1601336 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.3903556 Train accuary: 0.9084507042253521\n",
      "Val loss: 3.147007 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.3740697 Train accuary: 0.9084507042253521\n",
      "Val loss: 3.1357396 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.3594537 Train accuary: 0.9084507042253521\n",
      "Val loss: 3.126013 Val accuary: 0.8333333333333334\n",
      "----------------------------\n",
      "Train loss: 4.3462296 Train accuary: 0.9084507042253521\n",
      "Val loss: 3.117571 Val accuary: 0.8611111111111112\n",
      "----------------------------\n",
      "Train loss: 4.334179 Train accuary: 0.9154929577464789\n",
      "Val loss: 3.1102064 Val accuary: 0.8611111111111112\n",
      "----------------------------\n",
      "Train loss: 4.3231316 Train accuary: 0.9225352112676056\n",
      "Val loss: 3.1037483 Val accuary: 0.8611111111111112\n",
      "----------------------------\n",
      "Train loss: 4.3129478 Train accuary: 0.9366197183098591\n",
      "Val loss: 3.0980577 Val accuary: 0.8611111111111112\n",
      "----------------------------\n",
      "Train loss: 4.303517 Train accuary: 0.9436619718309859\n",
      "Val loss: 3.0930188 Val accuary: 0.8611111111111112\n",
      "----------------------------\n",
      "Train loss: 4.2947454 Train accuary: 0.9507042253521126\n",
      "Val loss: 3.0885353 Val accuary: 0.8888888888888888\n",
      "----------------------------\n",
      "Train loss: 4.286559 Train accuary: 0.9577464788732394\n",
      "Val loss: 3.0845277 Val accuary: 0.8888888888888888\n",
      "----------------------------\n",
      "Train loss: 4.278893 Train accuary: 0.9647887323943662\n",
      "Val loss: 3.0809276 Val accuary: 0.8888888888888888\n",
      "----------------------------\n",
      "Train loss: 4.2716928 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0776777 Val accuary: 0.8888888888888888\n",
      "----------------------------\n",
      "Train loss: 4.2649145 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0747306 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2585173 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0720444 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.252467 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0695841 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.246735 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0673194 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.241295 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0652246 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2361226 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0632772 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2311997 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0614583 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2265067 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0597515 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.222028 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0581415 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.217749 Train accuary: 0.971830985915493\n",
      "Val loss: 3.0566173 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2136564 Train accuary: 0.971830985915493\n",
      "Val loss: 3.055167 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.209739 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0537817 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2059865 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.052453 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.2023864 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0511746 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.1989326 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0499399 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.1956153 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0487437 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.1924267 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0475817 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.1893606 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0464492 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.18641 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0453444 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.1835694 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.0442624 Val accuary: 0.9166666666666666\n",
      "----------------------------\n",
      "Train loss: 4.180833 Train accuary: 0.9788732394366197\n",
      "Val loss: 3.043202 Val accuary: 0.9166666666666666\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epcho in range(500):\n",
    "        _, loss, y_pred = sess.run([train_step, cross_entropy, output], feed_dict=feed_dict_train)\n",
    "        accuracy = (np.sum((np.argmax(y_pred, 0) == np.argmax(Y_train.values.T, 0))))/Y_train.shape[0]\n",
    "        \n",
    "        loss_val = cross_entropy.eval(feed_dict=feed_dict_val)\n",
    "        y_pred_val = output.eval(feed_dict=feed_dict_val)\n",
    "        accuaray_val = (np.sum((np.argmax(y_pred_val, 0) == np.argmax(Y_val.values.T, 0))))/Y_val.shape[0]\n",
    "        if epcho % 10 == 0:\n",
    "            print(\"Train loss:\", loss,\n",
    "                  \"Train accuary:\", accuracy)\n",
    "            print(\"Val loss:\", loss_val,\n",
    "                  \"Val accuary:\", accuaray_val)\n",
    "            print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
